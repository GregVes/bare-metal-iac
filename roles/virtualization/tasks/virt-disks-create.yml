- name: create disk images
  tags:
    - virt_disks_create
  block:
  - name: check if working dir directory exist
    stat:
      path: "{{ virt_working_dir }}"
    register: working_dir
    become_user: "{{ virt_admin }}"
    become: true

  - name: check if VMs are already running
    virt:
      command: list_vms
      state: running
    register: running_vms
    become_user: "{{ virt_admin }}"
    become: true

  - name: check vms list result
    debug:
      var: running_vms

  - name: create node disks directory
    file:
      path: "{{ virt_disks_path }}"
      state: directory
      mode: 0770
    become_user: "{{ virt_admin }}"
    become: true
    when: working_dir.stat.exists == False

  - name: create virt config directory
    file:
      path: "{{ virt_config_path }}"
      state: directory
      mode: 0770
    become_user: "{{ virt_admin }}"
    become: true
    when: working_dir.stat.exists == False

  - name: check if master node disk image exists
    stat:
      path: "{{ master_node_disk_path }}"
    register: master_disk_image
    become_user: "{{ virt_admin }}"
    become: true

  - name: download k8s master node disk image if not exist
    get_url:
      url: "{{ virt_disk_url }}"
      dest: "{{ master_node_disk_path }}"
    become_user: "{{ virt_admin }}"
    become: true
    when: master_disk_image.stat.exists == False

  - name: check if worker nodes disk images exist
    stat:
      path: "{{ item.main_disk_path }}"
    register: worker_disks_images
    become_user: "{{ virt_admin }}"
    become: true
    with_items: "{{ worker_nodes }}"

  - name: download worker nodes disk images if not exist
    get_url:
      url: "{{ virt_disk_url }}"
      dest: "{{ item[1].main_disk_path  }}"
    become: true
    when: item[0].stat.exists == False
    with_together:
      - "{{ worker_disks_images.results }}"
      - "{{ worker_nodes }}"

  # disable because of https://github.com/openebs/openebs/issues/3495
  # - name: create master additional disks for storage
  #   community.general.filesize:
  #     path: "{{ master_node_additional_disk_path }}"
  #     size: "{{ master_node_disk_size }}"
  #   become_user: "{{ virt_admin }}"
  #   become: true
  #   when: master_disk_image.stat.exists == False

  # - name: create workers additional disks for storage
  #   community.general.filesize:
  #     path: "{{ item.additional_disk_path }}"
  #     size: "{{ item.size }}"
  #   become_user: "{{ virt_admin }}"
  #   become: true
  #   when: master_disk_image.stat.exists == False
  #   with_items: "{{ worker_nodes }}"

  - name: resize master node disks
    shell: |
      sudo qemu-img resize "{{ master_node_disk_path }}" "{{ master_node_disk_size }}"G
    become_user: "{{ virt_admin }}"
    become: true
    when: master_node_hostname not in running_vms['list_vms']

  - name: resize workers nodes disk
    shell: |
      sudo qemu-img resize "{{ item.main_disk_path }}" "{{ item.size }}"G
    become: true
    when: item.hostname not in running_vms['list_vms']
    with_items: "{{ worker_nodes }}"

  # disable because of https://github.com/openebs/openebs/issues/3495
  # - name: convert master additional disk into raw format
  #   shell: |
  #     sudo qemu-img create -f raw "{{ master_node_additional_disk_path }}" "{{ master_node_disk_size }}"G
  #   become: true
  #   when: master_node_hostname not in running_vms['list_vms']

  # - name: convert workers' additional disk into raw format
  #   shell: |
  #     sudo qemu-img create -f raw "{{ item.additional_disk_path }}" "{{ item.size }}"G
  #   become: true
  #   when: item.hostname not in running_vms['list_vms']
  #   with_items: "{{ worker_nodes }}"

  - name: copy master network interfaces file into host
    template:
      src: virt-interfaces-master.j2
      dest: "{{ virt_config_path }}/00-net-config-k8s-master"
    become_user: "{{ virt_admin }}"
    become: true
    when: master_domain_name not in running_vms['list_vms']

  - name: copy worker nodes network interfaces file into host
    template:
      src: "{{ item.network_config_file_name }}"
      dest: "{{ virt_config_path }}/{{ item.network_config_file_host_dest }}"
    become_user: "{{ virt_admin }}"
    become: true
    when: item.hostname not in running_vms['list_vms']
    with_items: "{{ worker_nodes }}"

  - name: copy /etc/resolv.conf in host
    copy:
      src: resolv.conf
      dest: "{{ virt_config_path }}/resolv.conf"
    become: true
    when: running_vms["list_vms"] | length == 0

  - name: check if ssh keypair exists
    stat:
      path: "/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}"
    become_user: "{{ virt_admin }}"
    become: true
    register: ssh_key

  - name: generate ssh keypair
    openssh_keypair:
      path: "/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}"
      force: true
    when: ssh_key.stat.exists == False
    become_user: "{{ virt_admin }}"
    become: true

  - name: copy ssh private key to control node
    fetch:
      src: "/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}"
      dest: "{{ dest_ssh_key_pair }}"
      flat: true
    when: ssh_key.stat.exists == False
    become_user: "{{ virt_admin }}"
    become: true

  - name: remove known hosts leftovers from previous configs
    shell: |
      ssh-keygen -f "/home/{{ virt_admin }}/.ssh/known_hosts" -R "51.83.150.197"
      ssh-keygen -f "/home/{{ virt_admin }}/.ssh/known_hosts" -R "51.83.147.42"
      ssh-keygen -f "/home/{{ virt_admin }}/.ssh/known_hosts" -R "51.83.179.16"
    become_user: "{{ virt_admin }}"
    become: true

  - name: copy ssh public key to control node
    fetch:
      src: "/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}.pub"
      dest: "{{ dest_ssh_key_pair }}"
      flat: true
    when: ssh_key.stat.exists == False
    become_user: "{{ virt_admin }}"
    become: true

  - name: Set correct permission on ssh private key on control node
    file:
      path: "{{ dest_ssh_key_pair }}{{ ssh_key_name }}"
      mode: 0600
    delegate_to: localhost

  - name: Set correct permission on ssh public key on control node
    file:
      path: "{{ dest_ssh_key_pair }}{{ ssh_key_name }}.pub"
      mode: 0644
    delegate_to: localhost

  - name: customize - root password, timezone, hostname, copy network config and resolv.conf, copy k8s components script - master node image
    shell: |
      sudo virt-customize  \
        -a "{{ master_node_disk_path }}" \
        --root-password password:"{{ virt_root_password }}" \
        --timezone "{{ virt_timezone }}" \
        --hostname "{{ master_node_hostname }}" \
        --copy-in "{{ virt_config_path }}/00-net-config-k8s-master:/etc/network/interfaces.d/" \
        --copy-in "{{ virt_config_path }}/resolv.conf:{{ resolv_conf_path }}" \
        --ssh-inject "root:file:/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}.pub" \
        --run-command "DEBIAN_FRONTEND=noninteractive dpkg-reconfigure openssh-server"
    become_user: "{{ virt_admin }}"
    become: true
    when: master_domain_name not in running_vms['list_vms']

  - name: customize - root password, timezone, hostname, copy k8s components script - worker nodes images
    shell: |
      sudo virt-customize \
        -a "{{ item.main_disk_path }}" \
        --root-password password:"{{ virt_root_password }}" \
        --timezone "{{ virt_timezone }}" \
        --hostname "{{ item.hostname }}" \
        --copy-in "{{ virt_config_path }}/{{ item.network_config_file_host_dest }}:/etc/network/interfaces.d/" \
        --copy-in "{{ virt_config_path }}/resolv.conf:{{ resolv_conf_path }}" \
        --ssh-inject "root:file:/home/{{ virt_admin }}/.ssh/{{ ssh_key_name }}.pub" \
        --run-command "DEBIAN_FRONTEND=noninteractive dpkg-reconfigure openssh-server"
    become_user: "{{ virt_admin }}"
    become: true
    when: item.hostname not in running_vms['list_vms']
    with_items: "{{ worker_nodes }}"

  - name: allow bridged traffic
    lineinfile:
      path: "{{ firewall_before_rules_file }}"
      insertafter: "^# End required lines"
      regexp: "^-I FORWARD -m physdev --physdev-is-bridged -j ACCEPT"
      line: "-I FORWARD -m physdev --physdev-is-bridged -j ACCEPT"
    become: true
    when: running_vms["list_vms"] | length == 0

  - name: add virt admin to libvirt group
    user:
      append: yes
      groups: libvirt,kvm
      name: "{{ virt_admin }}"
    become: true
    when: running_vms["list_vms"] | length == 0

  - name: set the virt_admin as user for QEMU processes
    lineinfile:
      path: "{{ qemu_conf }}"
      regexp: ^user = "root"
      line: user = "{{ virt_admin }}"
    become: true
    when: running_vms["list_vms"] | length == 0
  when: inventory_hostname in groups["kvm_host"]